{
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Get all libraries"
      ],
      "metadata": {
        "id": "zmlxjqfbf6CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate -q\n",
        "!pip install transformers evaluate wandb -q"
      ],
      "metadata": {
        "id": "w90aDuL1TXSl",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:19:43.231484Z",
          "iopub.execute_input": "2023-06-06T12:19:43.231976Z",
          "iopub.status.idle": "2023-06-06T12:20:07.272378Z",
          "shell.execute_reply.started": "2023-06-06T12:19:43.231940Z",
          "shell.execute_reply": "2023-06-06T12:20:07.271250Z"
        },
        "trusted": true,
        "outputId": "5ff6bdc9-993b-474a-ba7f-3982e338af6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import IterableDataset, Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import wandb\n",
        "import random\n",
        "import os\n",
        "\n",
        "def seed_everything(seed: int):   \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "yE5C-gs0S-YY",
        "execution": {
          "iopub.status.busy": "2023-06-06T13:00:43.456832Z",
          "iopub.execute_input": "2023-06-06T13:00:43.457273Z",
          "iopub.status.idle": "2023-06-06T13:00:43.480014Z",
          "shell.execute_reply.started": "2023-06-06T13:00:43.457235Z",
          "shell.execute_reply": "2023-06-06T13:00:43.473566Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "I'l try to use most basic BERT"
      ],
      "metadata": {
        "id": "q9wozV31gDAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "4c67514b9b3d49ffb91632916c0b159b",
            "7fc2ac40c7cf4fc59e5dbaa4735a0ff1",
            "41d989d4c99f472586ccab26fc4e6f5a",
            "00d0f196e29b42f786a7ab3921c280af"
          ]
        },
        "id": "JSa1MWBTgB_z",
        "outputId": "78c7e201-0c5c-4305-b1bc-9f708714da2c",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:20:10.880955Z",
          "iopub.execute_input": "2023-06-06T12:20:10.881656Z",
          "iopub.status.idle": "2023-06-06T12:20:25.742682Z",
          "shell.execute_reply.started": "2023-06-06T12:20:10.881613Z",
          "shell.execute_reply": "2023-06-06T12:20:25.741673Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c67514b9b3d49ffb91632916c0b159b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fc2ac40c7cf4fc59e5dbaa4735a0ff1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41d989d4c99f472586ccab26fc4e6f5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00d0f196e29b42f786a7ab3921c280af"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataset\n",
        "So in here we have tokenized input (output) - `2+2=4` and masked input - `2+2=[MASK]`"
      ],
      "metadata": {
        "id": "kQiSw5N9f-nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "\n",
        "class NumbersDataset(Dataset):\n",
        "    def __init__(self, left_len, right_len, tokenizer):\n",
        "        super(NumbersDataset, self).__init__()\n",
        "        self.left_len = left_len\n",
        "        self.right_len = right_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self._build()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs.input_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.inputs.items()}\n",
        "\n",
        "    def _build(self):\n",
        "        self.inputs = []\n",
        "        self.masked = []\n",
        "        left_range = range(10**self.left_len)\n",
        "        right_range = range(10**self.right_len)\n",
        "        for i in product(left_range, right_range):\n",
        "            self.inputs.append(f'{i[0]}+{i[1]}={i[0]+i[1]}') # I'm really sorry for this mess\n",
        "            self.masked.append(f'{i[0]}+{i[1]}=[MASK]') # And this too\n",
        "        self.inputs = self.tokenizer(self.inputs)\n",
        "        self.masked = self.tokenizer(self.masked)\n",
        "        self.inputs['labels'] = self.inputs.input_ids.detach().clone()\n",
        "        self.inputs['input_ids'] = self.masked.input_ids.detach().clone()"
      ],
      "metadata": {
        "id": "nc2ZFyI2VEbu",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:20:25.748401Z",
          "iopub.execute_input": "2023-06-06T12:20:25.749611Z",
          "iopub.status.idle": "2023-06-06T12:20:25.763675Z",
          "shell.execute_reply.started": "2023-06-06T12:20:25.749575Z",
          "shell.execute_reply": "2023-06-06T12:20:25.762251Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can tweak max_length, I've tried 512 and it kinda worked, but was too slow"
      ],
      "metadata": {
        "id": "9hvpdHGJ3D7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tok(x):\n",
        "    return tokenizer(x, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
        "dataset = NumbersDataset(2, 2, tok)\n",
        "train_dataset, eval_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])"
      ],
      "metadata": {
        "id": "yJBRfaVHX3FR",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:20:25.765403Z",
          "iopub.execute_input": "2023-06-06T12:20:25.765950Z",
          "iopub.status.idle": "2023-06-06T12:20:32.681043Z",
          "shell.execute_reply.started": "2023-06-06T12:20:25.765911Z",
          "shell.execute_reply": "2023-06-06T12:20:32.680105Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick testing"
      ],
      "metadata": {
        "id": "kL0CkaiP3D7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(dataset[0]['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "7CfDzE6zbdkU",
        "outputId": "b027e8ce-f4e6-4bda-e7ad-c3287e809391",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:20:32.682489Z",
          "iopub.execute_input": "2023-06-06T12:20:32.682842Z",
          "iopub.status.idle": "2023-06-06T12:20:32.693180Z",
          "shell.execute_reply.started": "2023-06-06T12:20:32.682809Z",
          "shell.execute_reply": "2023-06-06T12:20:32.692233Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'[CLS] 0 + 0 = [MASK] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(dataset[0]['labels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "kp5K-8UsY6Nc",
        "outputId": "b5db4bbb-251d-4fc4-a8f5-a87e74992c50",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:20:32.694590Z",
          "iopub.execute_input": "2023-06-06T12:20:32.695002Z",
          "iopub.status.idle": "2023-06-06T12:20:32.702400Z",
          "shell.execute_reply.started": "2023-06-06T12:20:32.694956Z",
          "shell.execute_reply": "2023-06-06T12:20:32.701364Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'[CLS] 0 + 0 = 0 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparations"
      ],
      "metadata": {
        "id": "bNZWkgTt3D7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set some arguments"
      ],
      "metadata": {
        "id": "F0jnhFwY3D7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir='out',\n",
        "    per_device_train_batch_size=64,\n",
        "    num_train_epochs=2,\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy='steps'\n",
        ")"
      ],
      "metadata": {
        "id": "U394olmJZ3y4",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:42:16.282471Z",
          "iopub.execute_input": "2023-06-06T12:42:16.282869Z",
          "iopub.status.idle": "2023-06-06T12:42:16.293059Z",
          "shell.execute_reply.started": "2023-06-06T12:42:16.282837Z",
          "shell.execute_reply": "2023-06-06T12:42:16.292006Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define some metrics"
      ],
      "metadata": {
        "id": "wY3KlwUv3D7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "mae_metric = evaluate.load(\"mae\")"
      ],
      "metadata": {
        "id": "Diz-4hiMc3yz",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:42:17.226267Z",
          "iopub.execute_input": "2023-06-06T12:42:17.226616Z",
          "iopub.status.idle": "2023-06-06T12:42:17.705488Z",
          "shell.execute_reply.started": "2023-06-06T12:42:17.226586Z",
          "shell.execute_reply": "2023-06-06T12:42:17.704404Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## And train!"
      ],
      "metadata": {
        "id": "yK1QAAj-3D7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"llmcalc\",\n",
        "    \n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "        \"group\":\"e\",\n",
        "        \"model\":\"bert\",\n",
        "        \"name\":\"bert\"\n",
        "    }\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=mae_metric.compute,\n",
        "    # preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "UzaEu3zhaUBB",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:42:20.312737Z",
          "iopub.execute_input": "2023-06-06T12:42:20.313440Z",
          "iopub.status.idle": "2023-06-06T12:42:54.461728Z",
          "shell.execute_reply.started": "2023-06-06T12:42:20.313404Z",
          "shell.execute_reply": "2023-06-06T12:42:54.460886Z"
        },
        "trusted": true,
        "outputId": "39a28776-2e95-40d4-960c-0e5ebc85ae81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Finishing last run (ID:ak6udm8q) before initializing another..."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">worldly-energy-36</strong> at: <a href='https://wandb.ai/kwargs/llmcalc/runs/ak6udm8q' target=\"_blank\">https://wandb.ai/kwargs/llmcalc/runs/ak6udm8q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20230606_124104-ak6udm8q/logs</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Successfully finished last run (ID:ak6udm8q). Initializing new run:<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.15.3"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20230606_124220-211yh5c8</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/kwargs/llmcalc/runs/211yh5c8' target=\"_blank\">sunny-frost-37</a></strong> to <a href='https://wandb.ai/kwargs/llmcalc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/kwargs/llmcalc' target=\"_blank\">https://wandb.ai/kwargs/llmcalc</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/kwargs/llmcalc/runs/211yh5c8' target=\"_blank\">https://wandb.ai/kwargs/llmcalc/runs/211yh5c8</a>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bt = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "UVCCa2PbbR47",
        "outputId": "5a27743d-3fc3-49e9-e030-c73d6212efda",
        "execution": {
          "iopub.status.busy": "2023-06-06T12:43:06.762164Z",
          "iopub.execute_input": "2023-06-06T12:43:06.762633Z",
          "iopub.status.idle": "2023-06-06T12:46:48.791012Z",
          "shell.execute_reply.started": "2023-06-06T12:43:06.762594Z",
          "shell.execute_reply": "2023-06-06T12:46:48.790044Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 03:41, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.023500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.021000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.019100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.018400</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.018300</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "Mostly it's off by one"
      ],
      "metadata": {
        "id": "4Pxo-cwM3G1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EvalSet(Dataset):\n",
        "    def __init__(self, inputs):\n",
        "        self.inputs = inputs\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in tok(self.inputs).items()}\n",
        "\n",
        "tokenizer.decode(\n",
        "    trainer.predict(\n",
        "            EvalSet([\n",
        "                    \"41+25=[MASK]\"\n",
        "            ])\n",
        "    ).predictions.argmax(-1)[0]\n",
        ")"
      ],
      "metadata": {
        "id": "LpI8UXyhbqus",
        "execution": {
          "iopub.status.busy": "2023-06-06T13:18:12.233959Z",
          "iopub.execute_input": "2023-06-06T13:18:12.234357Z",
          "iopub.status.idle": "2023-06-06T13:18:12.276800Z",
          "shell.execute_reply.started": "2023-06-06T13:18:12.234323Z",
          "shell.execute_reply": "2023-06-06T13:18:12.275557Z"
        },
        "trusted": true,
        "outputId": "5974e6de-51fa-4258-ff73-79d61bb4bf1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "execution_count": 81,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'[CLS] 41 + 25 = 67 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
          },
          "metadata": {}
        }
      ]
    }
  ]
}